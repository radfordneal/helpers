HELPERS - A LIBRARY SUPPORTING COMPUTATIONS USING HELPER THREADS
          Implementation Documentation

Copyright (c) 2013 Radford M. Neal.

  The helpers library is free software; you can redistribute it and/or modify
  it under the terms of the GNU General Public License as published by
  the Free Software Foundation; either version 2 of the License, or
  (at your option) any later version.

  This program is distributed in the hope that it will be useful,
  but WITHOUT ANY WARRANTY; without even the implied warranty of
  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  GNU General Public License for more details.

  You should have received a copy of the GNU General Public License along
  with this program; if not, write to the Free Software Foundation, Inc.,
  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.


INTRODUCTION

This documentation describes how the helpers facility is implemented.

The current implementation is based on OpenMP, either version 3.0 or
version 3.1.  If OpenMP 3.0 is used, some atomicity properties that
the OpenMP 3.0 memory model does not mandate must be assumed, as
discussed below.  The implementation has been tested on Linux systems
running on Intel processors with gcc 4.6 and OpenMP 3.0 and with gcc
4.7 and OpenMP 3.1, and on a Solaris 10 system with a SPARCv9
processor using cc 5.12 with OpenMP 3.1.

Only a few OpenMP features are used: the parallel directive, the
threadprivate directive, the flush directive (without variable list),
the omp_get_thread_num procedure, and the omp_init_lock, omp_set_lock,
omp_test_lock, and omp_unset_lock procedures, plus for OpenMP 3.1, the
atomic read and atomic write directives.

No OpenMP directives or procedure calls appear in programs using the
helpers facility (if it is used as envisioned), so an implementation
not using OpenMP could be transparently substituted for the current
implementation.


MODEL FOR CONCURRENT MEMORY ACCESSES

The helpers implementation is designed to work with cached memory, in
which a write to memory by a thread is not necessarily seen (but may
be seen) by a different thread reading that location, unless the
writing thread does a flush operation after the write, and the reading
thread does a flush before its read and after the flush in the writing
thread.  The OpenMP 3.0 and 3.1 specifications guarantee the expected
result when write, flush, flush, and read operations occur in this
way.

When OpenMP 3.1 is used in this implementation (with none of the
ASSUMED_ATOMIC... options described below), correct operation should
be guaranteed, according to the OpenMP specification, with the
exception of the following provision in the OpenMP 3.1 specification:

  Accesses to variables smaller than the implementation defined
  minimum size or to C or C++ bit-fields may be implemented by
  reading, modifying, and rewriting a larger unit of memory, and may
  thus interfere with updates of variables or fields in the same unit
  of memory.  (page 14)

The helpers implementation assumes that the "minimum size" mentioned
is such that if a thread writes a non-compound C data type (char, int,
etc.), the value seen in some other thread at a different address,
that was not written to by this thread, will not change as a result,
even if the other thread may have written to the other address around
the same time, and these addresses are within a single C array or
structure (except that this is not assumed to be true when two threads
both write to bit fields within the same structure).  This is true of
Intel architecture processors, and probably also of all other
commonly-used processors.

The OpenMP 3.1 "atomic read" and "atomic write" directives are used
for any access to a variable that might occur simultaneously with an
access to the same variable in another thread, apart from simultaneous
read accesses, which may be done without use of "atomic read".  Such
atomic accesses are all either to signed or unsigned char variables or
to variables of type helpers_size_t, and are always done using one of
the macros ATOMIC_READ_CHAR, ATOMIC_WRITE_CHAR, ATOMIC_READ_SIZE, and
ATOMIC_WRITE_SIZE, which take an assignment statement as their
argument.  These macros by default expand to the OpenMP 3.1 "atomic
read" or "atomic write" directive followed by the assignment, with no
distinction between the "CHAR" and "SIZE" versions of the macros.

Since OpenMP 3.0 does not provide the "atomic read" and "atomic write"
directives that are available in OpenMP 3.1, the ATOMIC_READ_... and
ATOMIC_WRITE_... macros simply expand to the given statement when
OpenMP 3.0 is used.  In this situation, correctness of the helpers
implementation requires that reads and writes of variables of type
char (signed or unsigned) and of type helpers_size_t be atomic without
use of these directives, as a consequence of the machine architecture,
at least when aligned as they are by the C compiler.  That is, if one
thread writes such a value to some address while another thread reads
the value from that same address, without OpenMP synchronization, the
value read will either be the value before the write or the value that
was written.  Atomicity of simultaneous writes is not required, as
they do not occur in this helpers implementation.

The OpenMP specification is informal and open to interpretation.  An
expansive reading of it appears to be incompatible with the gcc
implementation for Intel processors, in which flush directives appear
to merely generate Intel "mfence" instructions (and perhaps disable
some reordering of operations that the compiler's optimizer might
otherwise have performed), which is not sufficient to ensure that data
in the cache has actually been stored in main memory.  This helpers
implementation therefore uses a somewhat conservative interpretation
of what OpenMP guarantees.

In particular, this implementation is compatible with there being a
"store buffer", which can lead to two threads both seeing their writes
as occurring before the other thread's write (even if OpenMP flush
directives that might be thought to eliminate this possibility are
present).  The unsynchronized data transfers done are unidirectional,
with one thread writing and another thread (or threads) reading, which
will operate correctly with a store buffer as long as the ordering of
writes and reads within one thread is preserved, which should be the
case when suitable OpenMP flush directives are used.

However, this implementation does assume that stores obey "transitive
visibility" (in the terminology of the Intel architecture manual).
Suppose that A, B, and C are initially zero, that Processor 1 sets A
to 1 and then (after a flush) sets B to 1 (and does a flush), that
Processor 2 sees (after a flush) that B is 1 and then sets C to 1 (and
does a flush), and that Processor 3 sees (after a flush) that C is 1
and then fetches A.  It is assumed that the value for A fetched by
Processor 3 is guaranteed to be 1.  This property is required for the
correctness by the mechanism the helpers implementation uses to delete
task entries, while replacing references to the deleted task as a
source of input by 0, as if it did not hold, it would be possible that
the task reading the input would see the 0 reference and assume that
all data was available to read, when it might not be.

Some OpenMP 3.1 implementations of "atomic read" and "atomic write"
are quite slow, even when it appears that no costly operations should
be necessary.  Since this can slow down the helpers implementation
considerably, the capability is provided to selectively disable use of
atomic directives by defining (eg, with a compiler option) one or more
of the symbols ASSUME_ATOMIC_READ_CHAR, ASSUME_ATOMIC_WRITE_CHAR,
ASSUME_ATOMIC_READ_SIZE, and ASSUME_ATOMIC_WRITE_SIZE.  Defining one
of these symbols disables the use of an atomic read or write directive
in the corresponding ATOMIC_... macro.  It is difficult to imagine how
a read of a single byte can be non-atomic on any contemporary computer
architecture, so defining ASSUME_ATOMIC_READ_CHAR at least ought to be
safe.

This helpers implementation does not rely on the flushes that are
implied by the OpenMP 3.1 atomic read and write directives - instead,
explicit flush operations are done wherever required - since there are
no atomic directives in OpenMP 3.0 (and it is not clear that the gcc
implementation of OpenMP 3.1 correctly implements such implicit
flushes in any case), and the atomic directives for OpenMP 3.1 might
have been disabled as described above.


WAIT POLICY

The helpers implementation tries to arrange that a thread waiting for
an event does so with as small overhead as possible (in particular,
with short latency to start once the event occurs), but also that a
thread that waits for an extended period of time (for example, while
the entire application is waiting for user input) does so without
consuming processor resources.  This requires that short waits be done
via loops, without a context switch to the operating system, but that
long waits relinquish the processor, to allow other threads of the
same application, or of an unrelated process, to run.

This implementation assumes that OpenMP is implemented with a similar
design goal, so that (at least for some suitable setting of the
OMP_WAIT_POLICY environment variable) a thread blocked waiting to set
a lock will initially loop, and hence wake up quickly if the lock is
released, but will relinquish the processor after some moderate number
of repetitions of this loop.  The helpers implementation tries to
reduce the overhead of some short waits further, by looping directly
without calling an OpenMP procedure such as omp_set_lock.  However,
the omp_set_lock procedure is usually called (perhaps after a moderate
amount of looping) in contexts where a very long wait may occur (eg,
when waiting for the next task to be scheduled by the master, which
could take arbitrarily long if the master is waiting for user input).
One exception is that the helper thread that will run the next task
may loop for an extended period of time checking for runnability of a
task if the only tasks that might run cannot run immediately because
they require completion of some master-only task.


DATA STRUCTURES AND LOCKS

The central data structure in the helpers implementation is an array
of structures recording data on tasks that are pending, that are
currently active, or that have completed but have not yet been noticed
to have completed by the master.  This array is indexed by task
indexes, from 1 to MAX_TASKS.  Index 0 is used for tasks that are
performed directly by the master (without ever being scheduled).
Entries in this 'task' array are created by the master thread, but
some fields may later be updated by helper threads.  Both the master
and helper threads read task entries.

A list of indexes of all outstanding tasks, in the order in which they
were scheduled, is maintained in the "used" array.  This array is read
and written only by the master thread, so no synchronization issues
arise with it.  Note that the "used" array will contain some tasks
that have completed, but have not been noticed by the master to have
completed.

Two circular queues of task indexes are maintained, as arrays in which
the number of entries is equal to MAX_TASKS+1, which must be a power
of two, so that increments modulo the size of the array can be quickly
done by adding and then and'ing with MAX_TASKS (which must be a power
of two minus one).  All tasks in these queues will also be present in
the "used" array.

The "master_only" queue holds indexes of pending master-only tasks, in
the order in which they were scheduled.  It is read and written only
in the master thread, with no need for synchronization.

The "untaken" queue holds indexes of scheduled tasks that are not
master-only and which have not yet been started, in arbitrary order.
Tasks are added to this queue only by the master thread.  Tasks may be
taken from the "untaken" queue by the master or a helper thread, with
exclusive access (to take a task to start, or for a merge operation)
controlled by "start_lock".

Two locks are maintained for use in a scheme that allows the helper
thread that has set start_lock to suspend itself, and later be woken
by the master thread when there may be something for the helper to do.
To avoid a race when a helper suspends itself just when the master is
scheduling a new task, the master sets untaken_lock when adding to the
untaken queue, and checks for suspension of the helper while the lock
is set, and the helper sets untaken_lock when deciding whether to
suspend due to the untaken queue being empty.


OPERATION OF THE MASTER THREAD

The master thread does the general operations of the application
program, schedules tasks to be done, and may sometimes do scheduled
tasks itself, or do master-now tasks (which are not scheduled in the
same sense as other tasks).  The design of the helpers implementation
tries to minimize overhead in the master thread, since it is the only
thread that can do many of these things, but some operations are done
in the master thread in order to avoid synchronization issues.

One role of the master is to "notice" that tasks have completed, at
which point they are removed from the 'task' array, and references to
them as sources of inputs are changed to zero, which is interpreted as
the task having completed (but the 'done' flag in a task entry not yet
removed can also indicate completion).  The application-defined macros
helpers_mark_not_in_use and helpers_mark_not_being_computed (if they
exist) are also called as appropriate when the master notices a task
has completed.  The master will notice tasks that have finished when
helpers_do_task, or any of the helpers_wait_... procedures are called,
as well as at other opportune times.

To schedule a new task (other than a master-now task), the master puts
it at the end of the "used" array, with a currently unused task index.
It also searches for tasks that are computing each of its input
variables, and records the most-recently-scheduled such task in the
"pipe" field of the new task's entry in the 'task' array.  Finally, it
adds the new task to either the "master_only" queue, or the "untaken"
queue.  Since only the master accesses the "used" array, and only the
master add tasks to these queues, this requires no synchronization
with helpers, except for the brief setting of untaken_lock described
above to avoid a suspension race.  

When a new task is added to the "untaken" queue, the master looks to
see if a helper has suspended itself because the "untaken" queue was
empty.  If so, this suspended helper is woken up.  Since this produces
some overhead in the master thread, a helper refrains from suspending
until the "untaken" queue has been empty for a moderate time.

When a task is scheduled, the application's helpers_mark_in_use and
helpers_mark_being_computed macros (if defined) are also called to
mark variables being used or computed by the new task.

When one of the helpers_wait_... procedures is called, the master
marks a subset of tasks (found from the "used" array) as being needed
(either to have started or to have completed) for this wait operation
to finish, by setting the "needed" field in the entries for these
tasks in the 'task' array.  These flags guide the helpers (and the
master) when deciding what task to run next.

After setting the "needed" flags in a wait procedure, the master loops
until no needed tasks remain to be done.  Within this loop, the master
notices tasks that have completed, and may do tasks itself.  When the
master does a (non-master-only) task, it performs the relevant subset
of the operations that a helper performs when doing a task, as
described next.  One difference, however, is that the master does not
use omp_set_lock on start_lock to gain exclusive access for taking a
task from the untaken queue, but instead gains access only when it is
currently possible by calling omp_test_lock, so that it will not
block.  Blocking for this reason might prevent the master from doing a
master-only task that later becomes runnable, which could cause
deadlock if another task needs the master-only task to complete before
it can run.  (Furthermore, even if there are not any master-only tasks
scheduled, blocking could slightly delay the master's return from
waiting.)

The helpers_start_computing_var procedure waits for helper threads to
start the needed tasks, so that the master can return as soon as
possible (and presumably use the data now being computed) - except
that it will do tasks itself if no helpers are idle or a master-only
task is needed.

When the master thread tries to merge tasks, it sets start_lock in
order to reliably check that the old task to merge with has not
started running, and to have exclusive access to the untaken queue
when removing a task that has become master-only or master-now after
the merge.


OPERATION OF A HELPER THREAD

A helper thread loops, looking for a task to run, running it, and then
setting the 'done' flag in the task entry to say that that task has
finished.  In detail, each helper repeatedly goes through the
following stages:

  1) Blocked trying to set start_lock, in order to look for a task to
     run.

  2) Once start_lock is set, it repeatedly checks to see if the
     'untaken' queue is empty.  This is done a maximum of SPIN_EMPTY
     times (a tuning constant) before the helper suspends itself (with
     start_lock still set, so other helpers will stay blocked too).

  3) If it suspends itself (with start_lock set), it will be woken by
     the master when a new task is added to the 'untaken' queue.

  4) When the 'untaken' queue is non-empty, it will repeatedly look
     for a runnable task (with start_lock set), from among those in
     the 'untaken' queue.  This check is done indefinitely, until
     completion of a task makes an existing task runnable, or a new
     task is scheduled that is runnable.

  5) Once a runnable task has been found, it runs it, after unsetting
     start_lock, and then sets the 'done' flag for the task.       

  6) Return to step 1.

Of course, at most one helper can have start_lock set.  The other
helpers will either be actively running a task, or will be blocked
trying to set start_lock (or will very shortly be doing one of these
things).


OPERATION OF A TASK PROCEDURE

A task procedure that does not handle pipelined input and does not
produced pipelined output operates without any interaction with other
threads.  It simply sets its output variable to something computed
from its input variables (and its helpers_op_t operand) and then
returns.  The output variable will not be accessed by any other task
during this computation, and the input variables will not be modified
by any other task.

A task procedure that produces pipelined output will from time to time
indicate that more of the output variable has been computed by calling
helpers_amount_out, which will store the helpers_size_t argument that
it is passed in the 'amt_out' field of the entry for this task in the
'task' array.  A flush is performed before setting 'amt_out', to
ensure that the promised data is actually visible to other threads at
the moment when the new 'amt_out' value is visible.

A task procedure receiving pipelined input will call helpers_avail0,
helpers_avail1, or helpers_avail2 to see how much input is available.
These procedures access fields in the task's entry in the 'task' array
that identify which task is computing each input variable (or 0 if no
task is computing the input, or the task that was computing it has
finished).  The amount of data so far produced for a variable can then
be found from the "amount_out" field of the entry for the task
computing that variable.  Completion of the task is signaled by the
'done' flag being set to one (or by the task index being zero).
Careful flush operations are needed to ensure correct operation when
the master notices completion of a task and sets the index of the task
computing the variable to 0 just as one of these procedures is called.

When more pipelined input for a task is not immediately available, the
the helpers_avail... procedure that was called checks repeatedly until
some more input is available, without blocking.

These operations are the same whether the task procedure is executing
in the master thread or a helper thread (operations in the master
would not need to take some of the precautions needed in helpers, but
this difference is not currently exploited).  For a task procedure
called directly from the master, all inputs must already have been
computed, so calls of pipelined input procedures return immediately.


COMPILE-TIME OPTIONS

The SPIN_EMPTY symbol and the ASSUME_ATOMIC_... symbols mentioned
above may be set when compiling helpers.c, perhaps most conveniently
with a compiler option.

The MAX_TASKS symbol, giving the maximum number of outstanding task
may also be defined.  Letting it default to its maximum of 255 is
probably usually best, but a smaller value (which must be a power of
two minus one) will prevent there being a large number of pending
tasks, which might sometimes be undesirable (eg, if these pending
tasks are preventing memory reclamation).

The ENABLE_TRACE symbol can be defined as 0, 1, 2, 3, or 4 to control
how much output is produced when tracing has been requested (by
calling helpers_trace).  A value of 0 disables all trace output, 1
produces normal output, 2 produces additional information (that can be
understood only by referring to the source code in helpers.c), 3
produces this additional information plus timing information, and 4
produces additional information on the entire set of tasks whenever a
task list is displayed.  Setting ENABLE_TRACE to 0 will save a small
amount of time when tracing is not enabled.  Values greater than 1
slow down operations, even when tracing is not enabled (with 3 or 4
producing greater slowdown than 2).

The ENABLE_STATS symbol can be defined as 0 or 1, with 0 disabling
statistics output (when helpers_stats is called), which saves a small
amount of time in some operations.
